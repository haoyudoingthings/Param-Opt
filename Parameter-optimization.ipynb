{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A toy stochastic cost function\n",
    "rng = np.random.default_rng(0)\n",
    "def cost(p_vec):\n",
    "    return sum([p**2 for p in p_vec]) + rng.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter dimension\n",
    "dp = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Differences Stochastic Approximation (FDSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simultaneous Perturbation Stochastic Approximation (SPSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nelder-Mead Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments can also be adaptive: gamma=1+2/dp, rho=0.75-1/(2*dp), sigma=1-1/dp (Adaptive Nelder-Mead Simplex (ANMS) method)\n",
    "def nelder_mead(cost, alpha=1, gamma=2, rho=0.5, sigma=0.5, nu=0.0001, max_iter=10000):\n",
    "    # Initial simplex\n",
    "    p_lst = [np.ones(dp)]\n",
    "    for i in range(dp):\n",
    "        temp = np.array(p_lst[0])\n",
    "        temp[i] += 1\n",
    "        p_lst.append(np.array(temp))\n",
    "    cost_lst = [cost(p_vec) for p_vec in p_lst]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # Order\n",
    "        cost_lst, p_lst = zip(*sorted(zip(cost_lst, p_lst))) # sort p_vec according to the cost function (ascending)\n",
    "\n",
    "        # Termination test\n",
    "        # Original termination criterion is based on the standard deviation of function values\n",
    "        # However, serious problems may arise with stochastic functions\n",
    "        # Another criterion is simplex size, ref: https://pubsonline.informs.org/doi/epdf/10.1287/mnsc.42.7.954\n",
    "        dist_lst = [norm(p - p_lst[0]) for p in p_lst[1:]]\n",
    "        if max(dist_lst) / max(1, norm(p_lst[0])) <= nu: # nu is the termination simplex size\n",
    "            break\n",
    "\n",
    "        # Centroid\n",
    "        p_o = sum(p_lst[:-1]) / dp # centroid of all points except the last one\n",
    "\n",
    "        # Reflection\n",
    "        p_r = p_o + alpha * (p_o - p_lst[-1]) # alpha > 0\n",
    "        cost_r = cost(p_r)\n",
    "        if cost_lst[0] <= cost_r and cost_r < cost_lst[-2]:\n",
    "            p_lst[-1] = p_r\n",
    "            cost_lst[-1] = cost_r\n",
    "            continue\n",
    "        \n",
    "        # Expansion\n",
    "        elif cost_r < cost_lst[0]:\n",
    "            p_e = p_o + gamma * (p_r - p_o) # gamma > 1\n",
    "            cost_e = cost(p_e)\n",
    "            if cost_e < cost_r:\n",
    "                p_lst[-1] = p_e\n",
    "                cost_lst[-1] = cost_e\n",
    "                continue\n",
    "            else:\n",
    "                p_lst[-1] = p_r\n",
    "                cost_lst[-1] = cost_r\n",
    "                continue\n",
    "        \n",
    "        # Contraction\n",
    "        else: # cost_lst[-2] <= cost_r\n",
    "            p_c = p_o + rho * (p_r - p_o) # 0 < rho <= 0.5\n",
    "            cost_c = cost(p_c)\n",
    "            if cost_r < cost_lst[-1]:\n",
    "                if cost_c < cost_r:\n",
    "                    p_lst[-1] = p_c\n",
    "                    cost_lst[-1] = cost_c\n",
    "                    continue\n",
    "            else: # cost_lst[-1] <= cost_r\n",
    "                if cost_c < cost_lst[-1]:\n",
    "                    p_lst[-1] = p_c\n",
    "                    cost_lst[-1] = cost_c\n",
    "                    continue\n",
    "        \n",
    "        # Shrink\n",
    "        # Rare case, takes a lot of cost function evaluations, possibly omittable\n",
    "        p_lst = [p_lst[0] + sigma * (p_vec - p_lst[0]) for p_vec in p_lst] # 0 < sigma <= 0.5\n",
    "        cost_lst = [cost(p_vec) for p_vec in p_lst]\n",
    "    \n",
    "    else:\n",
    "        # Optimization failed, number of iteration exceeds maximum value\n",
    "        return\n",
    "    \n",
    "    return p_lst[0], cost_lst[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
